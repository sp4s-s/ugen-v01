{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjNwO0mMUzt_",
        "outputId": "c9960a54-6928-4e34-8740-4354c62e2017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ugen-v01'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 36 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (36/36), 21.96 MiB | 16.92 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/sp4s-s/ugen-v01/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install huggingface_hub accelerate"
      ],
      "metadata": {
        "id": "vnNx5-E-W5WJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ugen-v01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Doo-tCtSW5Xd",
        "outputId": "599072f8-6de8-4c71-81d3-43b34b4122a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ugen-v01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python download.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t3bvzPywW5aL",
        "outputId": "5e72c56a-d390-4fd0-82c0-a2ebb51d5296"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amber-v1.zip: 100% 163M/163M [00:02<00:00, 77.9MB/s]\n",
            "Extracted JPGs from amber-v1.zip\n",
            "klee-v1.zip: 100% 109M/109M [00:01<00:00, 59.6MB/s]\n",
            "Extracted JPGs from klee-v1.zip\n",
            "nahida-v1.0.zip: 100% 158M/158M [00:01<00:00, 79.0MB/s]\n",
            "Extracted JPGs from nahida-v1.0.zip\n",
            "rushia-v2.zip: 100% 237M/237M [00:03<00:00, 76.1MB/s]\n",
            "Extracted JPGs from rushia-v2.zip\n",
            "shiroko-v1.zip: 100% 390M/390M [00:06<00:00, 62.6MB/s]\n",
            "Extracted JPGs from shiroko-v1.zip\n",
            "yoimiya-v1.zip: 100% 281M/281M [00:04<00:00, 70.3MB/s]\n",
            "Extracted JPGs from yoimiya-v1.zip\n",
            "collei-v1.zip: 100% 179M/179M [00:02<00:00, 71.3MB/s]\n",
            "Extracted JPGs from collei-v1.zip\n",
            "ganyu-v1.zip: 100% 256M/256M [00:03<00:00, 78.8MB/s]\n",
            "Extracted JPGs from ganyu-v1.zip\n",
            "hifumi-v1.zip: 100% 97.3M/97.3M [00:01<00:00, 65.4MB/s]\n",
            "Extracted JPGs from hifumi-v1.zip\n",
            "youmu-v1.zip: 100% 125M/125M [00:03<00:00, 37.8MB/s]\n",
            "Extracted JPGs from youmu-v1.zip\n",
            "azusa-blue-archive-v1.zip: 100% 305M/305M [00:04<00:00, 74.4MB/s]\n",
            "Extracted JPGs from azusa-blue-archive-v1.zip\n",
            "Failed on cuteniiji-sdxl-v1.zip: 404 Client Error. (Request ID: Root=1-6817a5b7-723efa817cddf71c6cd063e9;4ce34db9-66ec-42d7-be44-3a86adb01e1c)\n",
            "\n",
            "Entry Not Found for url: https://huggingface.co/datasets/hipete12/anime-image/resolve/main/cuteniiji-sdxl-v1.zip.\n",
            "nakiri-no-caption-v1.zip: 100% 218M/218M [00:03<00:00, 63.3MB/s]\n",
            "Extracted JPGs from nakiri-no-caption-v1.zip\n",
            "nayame-no_caption-v1.zip: 100% 218M/218M [00:02<00:00, 73.8MB/s]\n",
            "Extracted JPGs from nayame-no_caption-v1.zip\n",
            "Amiya-v1.zip: 100% 369M/369M [00:04<00:00, 74.0MB/s]\n",
            "Extracted JPGs from Amiya-v1.zip\n",
            "Blue_archive-IMari-v1.zip: 100% 144M/144M [00:01<00:00, 79.1MB/s]\n",
            "Extracted JPGs from Blue_archive-IMari-v1.zip\n",
            "Blue_archive-NAzusa-v1.1.zip: 100% 305M/305M [00:04<00:00, 72.8MB/s]\n",
            "Extracted JPGs from Blue_archive-NAzusa-v1.1.zip\n",
            "Blue_archive-Plana-v1.zip: 100% 237M/237M [00:03<00:00, 71.3MB/s]\n",
            "Extracted JPGs from Blue_archive-Plana-v1.zip\n",
            "Chenbin_style-v1.zip: 100% 694M/694M [00:09<00:00, 76.3MB/s]\n",
            "Extracted JPGs from Chenbin_style-v1.zip\n",
            "Chyoel-style-v1.zip: 100% 72.8M/72.8M [00:00<00:00, 77.1MB/s]\n",
            "Extracted JPGs from Chyoel-style-v1.zip\n",
            "Eromanga_sensei-Sagiri-v1.zip: 100% 129M/129M [00:01<00:00, 81.4MB/s]\n",
            "Extracted JPGs from Eromanga_sensei-Sagiri-v1.zip\n",
            "Genshin_impact-Hutao-v1.zip: 100% 761M/761M [00:10<00:00, 73.5MB/s]\n",
            "Extracted JPGs from Genshin_impact-Hutao-v1.zip\n",
            "Genshin_impact-Hutao-v2.zip: 100% 166M/166M [00:04<00:00, 38.2MB/s]\n",
            "Extracted JPGs from Genshin_impact-Hutao-v2.zip\n",
            "Kon-NAzusa-v1.zip: 100% 51.9M/51.9M [00:00<00:00, 72.8MB/s]\n",
            "Extracted JPGs from Kon-NAzusa-v1.zip\n",
            "Tatedadan_style-v1.zip: 100% 103M/103M [00:01<00:00, 78.2MB/s]\n",
            "Extracted JPGs from Tatedadan_style-v1.zip\n",
            "Tatedadan-style-v1.zip: 100% 103M/103M [00:01<00:00, 70.0MB/s]\n",
            "Extracted JPGs from Tatedadan-style-v1.zip\n",
            "VT-Hoshikawa-v1.zip: 100% 104M/104M [00:01<00:00, 73.8MB/s]\n",
            "Extracted JPGs from VT-Hoshikawa-v1.zip\n",
            "Bocchi_the_rock-IKita-v1.zip: 100% 221M/221M [00:02<00:00, 78.7MB/s]\n",
            "Extracted JPGs from Bocchi_the_rock-IKita-v1.zip\n",
            "Bocchi_the_rock-IKita-v2.zip: 100% 213M/213M [00:02<00:00, 76.8MB/s]\n",
            "Extracted JPGs from Bocchi_the_rock-IKita-v2.zip\n",
            "Bocchi_the_rock-YRyo-v2.zip: 100% 114M/114M [00:01<00:00, 63.3MB/s]\n",
            "Extracted JPGs from Bocchi_the_rock-YRyo-v2.zip\n",
            "Hoshi-style-v1.zip: 100% 279M/279M [00:03<00:00, 78.7MB/s]\n",
            "Extracted JPGs from Hoshi-style-v1.zip\n",
            "Failed on Anistyle-v1.22-linux.zip: 404 Client Error. (Request ID: Root=1-6817a611-05ed40ee179b62be11c7d12f;a5ab5c28-ff84-4cfb-b0f5-3ee767514282)\n",
            "\n",
            "Entry Not Found for url: https://huggingface.co/datasets/hipete12/anime-image/resolve/main/Anistyle-v1.22-linux.zip.\n",
            "Failed on Anistyle-v1.25.2-win.zip: 404 Client Error. (Request ID: Root=1-6817a611-26bedd333ce1fd991c4fbc63;d8bd04f6-5264-4ca5-b0a2-a6799c4b3e6b)\n",
            "\n",
            "Entry Not Found for url: https://huggingface.co/datasets/hipete12/anime-image/resolve/main/Anistyle-v1.25.2-win.zip.\n",
            "Fineria-style-v1.zip: 100% 322M/322M [00:06<00:00, 46.6MB/s]\n",
            "Extracted JPGs from Fineria-style-v1.zip\n",
            "Nemurinemu-style-v1.zip: 100% 36.4M/36.4M [00:00<00:00, 74.9MB/s]\n",
            "Extracted JPGs from Nemurinemu-style-v1.zip\n",
            "Egami-style-v3.zip: 100% 1.14G/1.14G [00:18<00:00, 62.4MB/s]\n",
            "Extracted JPGs from Egami-style-v3.zip\n",
            "Necomi-style-v1.zip: 100% 152M/152M [00:02<00:00, 70.0MB/s]\n",
            "Extracted JPGs from Necomi-style-v1.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rMufIYRXW5cj",
        "outputId": "7dde552b-5588-4de1-8c17-6ee819206d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-04 17:43:20.855899: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746380600.876244    3510 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746380600.882468    3510 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-04 17:43:20.902727: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpigsty\u001b[0m (\u001b[33mpigsty-na\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ugen-v01/wandb/run-20250504_174326-3nlsnk60\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgrievous-transport-5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pigsty-na/unet-image-gen\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/pigsty-na/unet-image-gen/runs/3nlsnk60\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "import torch, os, wandb\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from accelerate import Accelerator\n",
        "from unet import UNet\n",
        "from dataset import ImageNoiseDataset\n",
        "from utils import save_checkpoint, log_images\n",
        "\n",
        "\n",
        "data_path = \"data\"\n",
        "epochs = 50\n",
        "bs = 32\n",
        "lr = 5e-5\n",
        "checkpoint_dir = \"checkpoints\"\n",
        "\n",
        "wandb.init(project=\"unet-image-gen\")\n",
        "writer = SummaryWriter(\"runs/unet_image_gen\")\n",
        "accelerator = Accelerator()\n",
        "\n",
        "full = ImageNoiseDataset(data_path)\n",
        "train_ds, val_ds = random_split(full, [int(0.9*len(full)), len(full)-int(0.9*len(full))])\n",
        "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=bs)\n",
        "\n",
        "\n",
        "model = UNet()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "model, opt, train_dl, val_dl = accelerator.prepare(model, opt, train_dl, val_dl)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for step, (noise, target) in enumerate(train_dl):\n",
        "        pred = model(noise)\n",
        "        loss = torch.nn.functional.mse_loss(pred, target)\n",
        "        accelerator.backward(loss)\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        if step % 10 == 0 and accelerator.is_main_process:\n",
        "            wandb.log({\"loss\": loss.item()})\n",
        "            writer.add_scalar(\"Loss/train\", loss.item(), epoch * len(train_dl) + step)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0\n",
        "        for noise, target in val_dl:\n",
        "            pred = model(noise)\n",
        "            val_loss += torch.nn.functional.mse_loss(pred, target).item()\n",
        "        val_loss /= len(val_dl)\n",
        "\n",
        "        if accelerator.is_main_process:\n",
        "            wandb.log({\"val_loss\": val_loss})\n",
        "            writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
        "            save_checkpoint(model, f\"{checkpoint_dir}/unet_epoch_{epoch}.pt\")\n",
        "            log_images(noise[:4], pred[:4], target[:4], writer, epoch)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LllQUrxW5e8",
        "outputId": "75736230-a23f-412c-f724-ca1a711bc662"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UkuGHH5gW5hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xjX6enrcX0Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g2rSxhiZX0Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dGzebHGkX0Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L_zB76RZX0R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python inference.py"
      ],
      "metadata": {
        "id": "A-Od8zreX0Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nOn2qptkX0WH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDbfGHccX0oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ydHqos1WX0pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MrCgtVVsX0q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8TLdLAtFX0yx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}